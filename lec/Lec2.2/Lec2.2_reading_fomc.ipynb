{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reading Federal Reserve (FOMC) Statements with Python\n",
        "This notebook shows a practical, *Fed-watcher-friendly* workflow:\n",
        "\n",
        "1. Load a public corpus of FOMC communications directly from a **raw GitHub URL**\n",
        "2. Filter to **FOMC statements**\n",
        "3. Read a chosen statement and compare it to the previous one\n",
        "4. Run a few lightweight text analyses:\n",
        "   - sentence-level diffs (Git-style)\n",
        "   - added/removed sentences\n",
        "   - an illustrative \"hawk vs dove\" dictionary score\n",
        "   - keyword trends over time\n",
        "\n",
        "## Why raw GitHub links?\n",
        "A GitHub file link like:\n",
        "\n",
        "`https://github.com/USER/REPO/blob/main/path/file.csv`\n",
        "\n",
        "can usually be turned into a direct-download link by converting it to:\n",
        "\n",
        "`https://raw.githubusercontent.com/USER/REPO/main/path/file.csv`\n",
        "\n",
        "That means **no cloning** and no local files—great for teaching notebooks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data source\n",
        "We’ll use the open dataset maintained by `vtasca/fed-statement-scraping`, which scrapes Federal Reserve communications and stores them in a CSV.\n",
        "\n",
        "If the dataset schema changes over time, the notebook includes a small “column chooser” to map common column names to a standard set (`date`, `doc_type`, `title`, `text`).\n",
        "\n",
        "From this Repo:\n",
        "\n",
        "https://github.com/vtasca/fed-statement-scraping/tree/master\n",
        "\n",
        "We can access the CSV directly via this raw GitHub URL:\n",
        "\n",
        "https://raw.githubusercontent.com/vtasca/fed-statement-scraping/refs/heads/master/communications.csv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import difflib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the corpus from a raw GitHub URL (no cloning needed)\n",
        "FED_CORPUS_URL = \"https://raw.githubusercontent.com/vtasca/fed-statement-scraping/refs/heads/master/communications.csv\"\n",
        "\n",
        "fed = pd.read_csv(FED_CORPUS_URL)\n",
        "fed.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick inspection\n",
        "Before we do any analysis, we inspect the columns and a few random rows.\n",
        "\n",
        "This makes it easy to adapt if the dataset’s column names differ from what we expect.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Shape:\", fed.shape)\n",
        "print(\"Columns:\", list(fed.columns))\n",
        "\n",
        "# Sample a few rows (columns shown here may vary by dataset version)\n",
        "preview_cols = [c for c in [\"date\", \"type\", \"title\"] if c in fed.columns]\n",
        "fed.sample(5, random_state=0)[preview_cols].head() if preview_cols else fed.sample(5, random_state=0).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize key fields (date, doc_type, title, text)\n",
        "We map whatever the dataset uses into standard fields:\n",
        "\n",
        "- `date` → pandas datetime\n",
        "- `doc_type` → lowercase type label\n",
        "- `title` → title/headline\n",
        "- `text` → cleaned text\n",
        "\n",
        "The helper logic is intentionally simple and transparent for students.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82dfeeb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "fed[\"Date\"] = pd.to_datetime(fed[\"Date\"])\n",
        "fed[\"Type\"] = fed[\"Type\"].str.lower()\n",
        "fed[\"Text\"] = fed[\"Text\"].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter to FOMC statements\n",
        "Many corpora include other documents (minutes, transcripts, speeches, etc.).  \n",
        "We filter to rows whose `doc_type` includes the word `\"statement\"` and then sort by date.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "statements = (\n",
        "    fed\n",
        "    .query(\"Type == 'statement'\")\n",
        "    .sort_values(\"Date\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "statements[[\"Date\", \"Release Date\", \"Text\"]].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choose a statement to read\n",
        "By default we take the 2 latest statement in the dataset.\n",
        "\n",
        "These are December 2025 and October 2025 in the current data.\n",
        "\n",
        "You can also set `i` manually to read a different meeting:\n",
        "- `i = 0` is the earliest statement\n",
        "- `i = len(statements)-1` is the latest statement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current = statements.iloc[-1]\n",
        "previous = statements.iloc[-2]\n",
        "\n",
        "current[\"Date\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print statement text (truncated)\n",
        "Statements can be long. This prints the first 1,500 characters.  \n",
        "Feel free to increase the number if you want the full statement in the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(current[\"Text\"][:1500])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare to previous meeting (sentence-level diff)\n",
        "We split each statement into sentences, then compute a unified diff (like Git).\n",
        "This is a simple but powerful way to see what changed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sentence_split(text):\n",
        "    # Simple sentence split (good enough for class)\n",
        "    parts = re.split(r\"(?<=[.!?])\\s+\", text)\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "cur_sents = sentence_split(current[\"Text\"])\n",
        "prev_sents = sentence_split(previous[\"Text\"]) if previous is not None else []\n",
        "\n",
        "diff = difflib.unified_diff(\n",
        "    prev_sents, cur_sents,\n",
        "    fromfile=f\"prev ({previous['Date'].date()})\",\n",
        "    tofile=f\"curr ({current['Date'].date()})\",\n",
        "    lineterm=\"\"\n",
        ")\n",
        "\n",
        "# Show first ~200 diff lines\n",
        "for k, line in zip(range(200), diff):\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Added and removed sentences\n",
        "A more “digestible” view than the full diff:\n",
        "- sentences present now but not previously (`added`)\n",
        "- sentences present previously but not now (`removed`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cur_set = set(cur_sents)\n",
        "prev_set = set(prev_sents)\n",
        "\n",
        "added = [s for s in cur_sents if s not in prev_set]\n",
        "removed = [s for s in prev_sents if s not in cur_set]\n",
        "\n",
        "print(\"ADDED sentences:\\n\")\n",
        "for s in added[:10]:\n",
        "    print(\"-\", s)\n",
        "\n",
        "print(\"\\nREMOVED sentences:\\n\")\n",
        "for s in removed[:10]:\n",
        "    print(\"-\", s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8dfae4f",
      "metadata": {},
      "source": [
        "## A simple \"hawk vs dove\" dictionary score (illustrative)\n",
        "This is intentionally simple and transparent:\n",
        "- count occurrences of a small list of \"hawkish\" terms\n",
        "- subtract occurrences of a small list of \"dovish\" terms\n",
        "\n",
        "First lets define the lists of terms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee40e16",
      "metadata": {},
      "outputs": [],
      "source": [
        "HAWK = [\n",
        "    \"inflation\", \"strong\", \"tight\", \"raise\", \"increases\", \"restrictive\",\n",
        "    \"higher\", \"persistent\", \"upside risks\"\n",
        "]\n",
        "DOVE = [\n",
        "    \"patient\", \"accommodative\", \"support\", \"lower\", \"cut\", \"easing\",\n",
        "    \"downside risks\", \"slack\", \"moderation\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34fc8f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def hawk_count(text):\n",
        "    text = text.lower()\n",
        "    return sum(text.count(term) for term in HAWK)\n",
        "\n",
        "current_hawk = hawk_count(current[\"Text\"])\n",
        "current_hawk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a0af87",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Important:** This is not a validated research measure—just a class-friendly starting point.\n",
        "Students can improve it by:\n",
        "- adding/removing terms\n",
        "- building phrase matching\n",
        "- validating against eg recession indicators or external labels\n",
        "\n",
        "### Now we can compute a Hawk-Dove score = Hawk mentions - Dove mentions\n",
        "Is the statement more hawkish (positive score) or dovish (negative score) and how does it compare to the previous one?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def term_count(text, terms):\n",
        "    t = text.lower()\n",
        "    return sum(t.count(term) for term in terms)\n",
        "\n",
        "def hawk_dove_score(text):\n",
        "    return term_count(text, HAWK) - term_count(text, DOVE)\n",
        "\n",
        "current_score = hawk_dove_score(current[\"Text\"])\n",
        "prev_score = hawk_dove_score(previous[\"Text\"]) if previous is not None else np.nan\n",
        "\n",
        "print(\"Current score:\", current_score)\n",
        "print(\"Previous score:\", prev_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fc470e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def counts_breakdown(text):\n",
        "    return {\n",
        "        \"hawk\": term_count(text, HAWK),\n",
        "        \"dove\": term_count(text, DOVE),\n",
        "        \"score\": hawk_dove_score(text),\n",
        "    }\n",
        "\n",
        "print(\"CURRENT:\", counts_breakdown(current[\"Text\"]))\n",
        "print(\"PREV:   \", counts_breakdown(previous[\"Text\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the hawk–dove score over time\n",
        "This creates a simple time series so students can see:\n",
        "- long-run shifts in language\n",
        "- spikes around specific macro periods\n",
        "\n",
        "Again: interpret cautiously—this is a toy indicator meant for learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "statements[\"hawk_dove\"] = statements[\"Text\"].map(hawk_dove_score)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(statements[\"Date\"], statements[\"hawk_dove\"])\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.title(\"FOMC Statement Hawk–Dove Dictionary Score (Illustrative)\")\n",
        "plt.ylabel(\"hawk words − dove words\")\n",
        "plt.xlabel(\"\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keyword trends over time\n",
        "A second, very interpretable analysis: count keyword mentions.\n",
        "\n",
        "You can add macro-relevant terms like:\n",
        "- \"inflation\", \"labor\", \"financial conditions\"\n",
        "- \"uncertainty\", \"risks\", \"growth\"\n",
        "- \"balance sheet\", \"quantitative tightening\", etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KEYWORDS = [\"inflation\", \"labor\", \"employment\", \"unemployment\", \"financial conditions\"]\n",
        "\n",
        "for kw in KEYWORDS:\n",
        "    statements[kw] = statements[\"Text\"].str.lower().str.count(kw)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(statements[\"Date\"], statements[\"inflation\"], label=\"inflation\")\n",
        "plt.plot(statements[\"Date\"], statements[\"labor\"], label=\"labor\")\n",
        "plt.plot(statements[\"Date\"], statements[\"financial conditions\"], label=\"financial conditions\")\n",
        "plt.title(\"Keyword Mentions in FOMC Statements\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.xlabel(\"\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Student assignment prompts\n",
        "1) Pick a statement and identify **3 substantive changes** vs the previous statement. Quote the changed sentence(s).  \n",
        "2) Does the dictionary score move in the direction you’d expect given the macro context? Explain.  \n",
        "3) Choose 2 keywords and describe how their attention changes across time windows.  \n",
        "4) Optional: propose a better dictionary (5 hawk terms, 5 dove terms) and justify each term.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional extensions (for a follow-on lab)\n",
        "- TF‑IDF similarity between meetings\n",
        "- bigram extraction (“financial conditions”, “ongoing increases”, …)\n",
        "- paragraph-level diffs instead of sentence-level\n",
        "- merge statement dates with market data (FRED / Yahoo Finance) for an event-study\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c070945",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data-science-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
